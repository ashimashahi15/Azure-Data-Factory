Overview:
Data flows are one of the features inside the Azure Data Factory which allows data engineers to develop data transformation logic in a graphical approach 
without writing code. The resulting data flows can then be executed as activities within Azure Data Factory pipelines that use scaled-out Spark clusters. 
Your data flows will run on your own execution cluster for scaled-out data processing. ADF internally handles all the code translation, spark optimization
and execution of the transformation. Data flow activities can be operationalized via the existing Data Factory scheduling, control, flow, and monitoring capabilities.



There are two types of Data flows:

Mapping Data Flow
Wrangling Data Flow


Mapping Data Flow â€“
Mapping data flows are visually designed data transformations in Azure Data Factory.
When there is a situation where you need to perform transformations using two or more datasets then you use a Mapping data flow.
You can perform several transformations such as Filter, JOIN, Aggregate, Union, Lookup, Sort, etc using mapping data flows.
Mapping data flows can be executed within ADF pipelines using data flow activities.
Azure Data Factory handles the code transformation and execution of Mapping Data Flow behind the scenes.
Mapping Data Flows activity can be created individually or within an Azure Data Factory pipeline.

Wrangling Data Flow
Wrangling Data Flow uses the M query language and the Power Query Editor's UI. The developer can use the graphical user interface to handle all the 
tedious tasks with little to no coding using wrangling data flows. However, all the UI actions are transformed to the M language in the background. 
Azure Data Factory will convert the M code to Spark at runtime, running your data flow against large data clusters. This implies that you should expect
consistent performance as your data volumes increase.

Derived Column
In Azure Data Factory (ADF), you can use various functions to derive new columns or transform existing ones. These functions are typically utilized within Data Flow activities when defining expressions for derived columns. Here are some commonly used ADF functions for column derivation:

1. **concat():** Concatenates two or more strings together.

2. **substring():** Extracts a substring from a given string based on start index and length.

3. **trim():** Removes leading and trailing spaces from a string.

4. **upper():** Converts a string to uppercase.

5. **lower():** Converts a string to lowercase.

6. **replace():** Replaces occurrences of a substring with another substring within a given string.

7. **split():** Splits a string into an array of substrings based on a delimiter.

8. **length():** Returns the length of a string.

9. **isNull():** Checks if a column value is null and returns a default value if true.

10. **coalesce():** Returns the first non-null value from a list of columns.

11. **ifNull():** Returns a specified value if the column is null.

12. **iif():** Evaluates an expression and returns one of two values based on the result.

13. **year(), month(), day():** Extracts the year, month, or day from a date.

14. **dateAdd():** Adds a specified number of days, months, or years to a date.

15. **dateDiff():** Calculates the difference between two dates in days, months, or years.

16. **toDate():** Converts a string or numeric value to a date.

17. **toString():** Converts a numeric value or date to a string.

18. **int(), float(), decimal():** Converts a string to an integer, float, or decimal data type.

19. **trimStart(), trimEnd():** Removes leading or trailing spaces from a string.

20. **startsWith(), endsWith():** Checks if a string starts or ends with a specific substring.

These are just some of the functions available in ADF for column derivation. You can combine these functions and use conditional statements to perform complex transformations on your data within Data Flows. Remember to refer to the official Azure Data Factory documentation for the most up-to-date and comprehensive list of functions and their syntax.



Aggregate Trnasformation
In Azure Data Factory (ADF) Data Flow, the Aggregate transformation is used to perform group-based calculations on data. 
It allows you to group rows based on one or more columns and apply various aggregate functions to calculate values within each group.
The possible aggregate functions that can be implemented in a row using the Aggregate transformation in ADF Data Flow:

Sum: Calculates the sum of values within a group.
Count: Counts the number of rows within a group.
Average: Calculates the average of values within a group.
Minimum (Min): Finds the minimum value within a group.
Maximum (Max): Finds the maximum value within a group.
First: Retrieves the first value within a group.
Last: Retrieves the last value within a group.
Count Distinct: Counts the number of distinct values within a group.
Standard Deviation (StDev): Calculates the standard deviation within a group.
Variance: Calculates the variance within a group.
Approximate Count Distinct: Approximate count of distinct values within a group.
Approximate Sum: Approximate sum of values within a group.
Approximate Average: Approximate average of values within a group.


To implement these functions in a row, you need to configure the Aggregate transformation in ADF Data Flow and define the group-by columns 
reand the corresponding aggregate functions for each column. The output will contain one row per group with the aggregated results.
